{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "\n",
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(np.float)# ensure that the return np is float\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs,validation_targets = npz['inputs'].astype(np.float),npz['targets'].astype(np.int)\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - loss: 0.5461 - accuracy: 0.7863 - val_loss: 0.4472 - val_accuracy: 0.8546 - 1s/epoch - 30ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3785 - accuracy: 0.8729 - val_loss: 0.3715 - val_accuracy: 0.8635 - 57ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3282 - accuracy: 0.8826 - val_loss: 0.3448 - val_accuracy: 0.8725 - 56ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.3070 - accuracy: 0.8866 - val_loss: 0.3289 - val_accuracy: 0.8837 - 59ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.2943 - accuracy: 0.8919 - val_loss: 0.3178 - val_accuracy: 0.8881 - 62ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.2845 - accuracy: 0.8947 - val_loss: 0.3116 - val_accuracy: 0.8926 - 72ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2756 - accuracy: 0.9005 - val_loss: 0.3015 - val_accuracy: 0.8904 - 54ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2677 - accuracy: 0.8994 - val_loss: 0.2941 - val_accuracy: 0.8904 - 51ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2626 - accuracy: 0.9025 - val_loss: 0.2890 - val_accuracy: 0.8881 - 44ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2567 - accuracy: 0.9053 - val_loss: 0.2857 - val_accuracy: 0.8904 - 47ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2530 - accuracy: 0.9061 - val_loss: 0.2846 - val_accuracy: 0.8926 - 50ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.2514 - accuracy: 0.9067 - val_loss: 0.2861 - val_accuracy: 0.8926 - 60ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.2483 - accuracy: 0.9072 - val_loss: 0.2852 - val_accuracy: 0.8926 - 56ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c525371f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_size = 10 input layer\n",
    "output_size = 2 # expected target is either 1 or 2 hence 2\n",
    "hidden_layer = 50 # the middle portion of the neural network\n",
    "\n",
    "model = tf.keras.Sequential([   \n",
    "    tf.keras.layers.Dense(hidden_layer,activation = 'relu'),#first layer\n",
    "    tf.keras.layers.Dense(hidden_layer,activation = 'relu'),#second layer\n",
    "    tf.keras.layers.Dense(output_size,activation = 'softmax')#transform it to probability softmax\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',loss ='sparse_categorical_crossentropy',metrics = ['accuracy']) # configure the model for training\n",
    "#loss is this method as it is category\n",
    "\n",
    "#\n",
    "batch_size = 100\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience = 2) # ensure our model does not overfit \n",
    "#the data monitor the validation loss and stop the training the first time the validation loss increase \n",
    "#patience is for tolerance as validation loss might increase by chance.\n",
    "\n",
    "#keras.sequential laying down the model different layers of we want in our model\n",
    "#keras.layers.dense takes the input from the last layer calculate their dot product with the weights and add bias.\n",
    "#second argument is activation\n",
    "\n",
    "\n",
    "model.fit(train_inputs,\n",
    "         train_targets,\n",
    "         batch_size = batch_size,\n",
    "         epochs = max_epochs,\n",
    "         callbacks = [early_stop],\n",
    "         validation_data = (validation_inputs,validation_targets),\n",
    "         verbose = 2)\n",
    "\n",
    "#verbose indicate how detailed our training report should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the data\n",
    "\n",
    "#validation set ensure that our parameters (the weight and biases) do not overfit\n",
    "#test make sure our hyperparameter(width,depth.etc)dont overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.8926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss,test_accuracy = model.evaluate(test_inputs,test_targets) #return the loss value and metrics values for the model in test mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#90 percent means 9 out of 10 people will purchase the book again\n",
    "model.predict(test_inputs).round(2)\n",
    "#each row represent a different observation\n",
    "#each column represent the output as for this example the left is probability to be classified as zero\n",
    "#while the right side is probability to be classified as one\n",
    "\n",
    "\n",
    "#converting\n",
    "model.predict(test_inputs)[:,1].round(0)\n",
    "\n",
    "#Argmax is an operation that finds the argument that gives the maximum value from a target function\n",
    "\n",
    "np.argmax(model.predict(test_inputs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('audiobook_portfolio.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
